{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load voxel data\n",
    "\n",
    "These are 2322 voxels with 200 time slices with a 2 sec TR.  \n",
    "20 images belonging to 1 of 4 classes are shown in block trials.\n",
    "The images are on for .3 seconds and off for .5 seconds. 20*.8 s = 16 second blocks.\n",
    "Since TR=2, there are exactly 8 images per block.\n",
    "This data has been polynomial detrended and motion corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = loadmat('../data/logisticdata.mat')\n",
    "voxels = data['voxeldata']\n",
    "trials = data['trials']\n",
    "n_t = len(trials)  # Number of time slices = 200\n",
    "TR = 2  # TR in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Load voxel data. \n",
    "# # These are 2322 voxels with 200 time slices with a 2 sec TR.  \n",
    "# # 20 images belonging to 1 of 4 classes are shown in block trials.\n",
    "# # The images are on for .3 seconds and off for .5 seconds. 20*.8 s = 16 second blocks.\n",
    "# # Since TR=2, there are exactly 8 images per block.\n",
    "# # This data has been polynomial detrended and motion corrected.\n",
    "# load ../data/logisticdata.mat\n",
    "# nt = length(trials);                  # Number of time slices = 200\n",
    "# TR = 2;  # TR in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make indicies for the different stimulus types: blanks, places, faces, objects\n",
    "ixs_blank = np.where(trials == 0)\n",
    "ixs_places = np.where(trials == 1)\n",
    "ixs_faces = np.where(trials == 2)\n",
    "ixs_objects = np.where(trials == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Make indicies for the different stimulus types: blanks, places, faces, objects\n",
    "# blankidx = find(trials==0);\n",
    "# placesidx = find(trials==1);\n",
    "# facesidx = find(trials==2);\n",
    "# objectidx = find(trials==3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "Plot the trials to understand how the experiment was\n",
    "performed.  You might want to try plotting using plot(trials) and\n",
    "imagesc(trials')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are going to test for a binary stimulus classification of faces (1) and non-faces (0). \n",
    "# After you run finish the exercise you will try other classifications!\n",
    "stimclas = np.zeros([1, n_t])\n",
    "stimclas[0, ixs_faces] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are now going to use sklearn to perform the logistic regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MATLAB CODE - DELETE ONCE ITS CONVERTED\n",
    "# ## We are going to test for a binary stimulus classification of faces (1) and non-faces (0). \n",
    "# #  After you run finish the exercise you will try other classifications!\n",
    "# stimclass = zeros(1,nt);\n",
    "# stimclass(facesidx) = 1;\n",
    "\n",
    "# ## We are now going to use strflab to perform the logistic regresssion\n",
    "# # Declare the global Data variable that strflab uses\n",
    "# global globDat;\n",
    "\n",
    "# Put data in global variable. We are going to be predicting stimulus class from voxel responses, so the \n",
    "# voxel responses should go in the \"Stimulus\" variable and stimulus class goes in the \"response\" variable\n",
    "strfData(voxeldata', stimclass');\n",
    "\n",
    "# Note that delay is negative because voxel responses come after the\n",
    "# stimulus class!\n",
    "ndel = 8;      # 8 time slices or 16 seconds - this is also equal to the time the stimulus is on?\n",
    "strf = linInit(size(globDat.stim,2), -ndel:0, 'logistic');\n",
    "\n",
    "# Create an options structure\n",
    "options = trnGradDesc;\n",
    "options.coorDesc=0;\n",
    "options.earlyStop=0;\n",
    "options.stepSize = 1e-2;\n",
    "options.display = 1;\n",
    "\n",
    "# We are going to train for the first 150 samples and predict on the last 50 samples\n",
    "trainIdx = 1:150;\n",
    "valIdx = 151:200;\n",
    "\n",
    "## Fit the strf\n",
    "strfTrained = strfOpt(strf, trainIdx, options);\n",
    "\n",
    "## Use the fit strf to make a prediction on the validation set\n",
    "[strfTrained, pred] = strfFwd(strfTrained, valIdx);\n",
    "\n",
    "## Visualize prediction and actual stimulus class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "On figure 2, show the prediction and the actual image classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## We can also plot the weight distribution\n",
    "figure(3);\n",
    "sw = sum(abs(strfTrained.w1(:,1,:)),3);\n",
    "plot(sw);\n",
    "\n",
    "## And find the voxel with the highest weights to plot the time course\n",
    "\n",
    "idx = find(sw == max(sw));\n",
    "figure(4);\n",
    "t=0:ndel;\n",
    "t=t*TR;\n",
    "plot(t,squeeze(strfTrained.w1(idx,1,:)));\n",
    "xlabel('Time (s)');\n",
    "ylabel('Weight');\n",
    "title(sprintf('Weight time course for voxel #d\\n', idx));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly to model is working somewhat, but it is predicting faces where there aren't any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3.\n",
    "\n",
    "Repeat the previous using early stopping (see our gradient descent tutorials)\n",
    "Remember that you will also have to specify a stopping index. After\n",
    "fitting the model, 1) use strfFwd to obtain predictions, 2) plot the\n",
    "results (fugure 5), 3) plot the weight distribution as above. (figure\n",
    "6) 4) plot the time course of the weights as above (figure 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.\n",
    "Repeat the fit using coordinate descent.  Plot the fit on \n",
    "figure 8 and the weight distribution on figure 9 and the time course of figure 10.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Exercise 5. On figure 11, for the voxel with the largest weight,\n",
    "# plot the average response (for the 8 time points) \n",
    "# in blocks containing faces and compare that to the average response."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
